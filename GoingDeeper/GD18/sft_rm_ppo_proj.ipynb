{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e245b0",
   "metadata": {},
   "source": [
    "# KoChatGPT SFT+RLHF 실습 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05bbf64",
   "metadata": {},
   "source": [
    "#### __할 일__\n",
    "  - Back bone 모델 교체;  \n",
    "    - SFT모델, 리워드 모델, actor/critic모델  \n",
    "  - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8151c8b0",
   "metadata": {},
   "source": [
    "__한 일__\n",
    "  - generator선언 시 'pipeline'클래스의 초기화 인자 'model' 세팅\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689c8a2",
   "metadata": {},
   "source": [
    "__결과__\n",
    "  - SFT에 들어가는 QnA 입력 형태가 이전 GPT chatbot의 경우와 다르다.  \n",
    "    타겟 데이터에 Q부분을 마스킹 처리하는 것.\n",
    "  - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43cac99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import logging\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from datasets import load_dataset\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d519f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "# model_name = \"skt/ko-gpt-trinity-1.2B-v0.5\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9384e9ea",
   "metadata": {},
   "source": [
    "#### 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "494122bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15c36c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    # 특수 토큰들을 '</s>'로 통일한 이유가 있는 걸까?\n",
    "    # 설정을 바꾸면 vocab크기가 달라져 오류 발생; CUBLAS_STATUS_NOT_INITIALIZED\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    # 'skt/kogpt2-base-v2', bos_token='<s>', eos_token='</s>', unk_token='<u>', pad_token='<p>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997bab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Config {\n",
      "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.28.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "transformer.wte.weight --- torch.Size([51200, 768])\n",
      "transformer.wpe.weight --- torch.Size([1024, 768])\n",
      "transformer.h.0.ln_1.weight --- torch.Size([768])\n",
      "transformer.h.0.ln_1.bias --- torch.Size([768])\n",
      "transformer.h.0.attn.c_attn.weight --- torch.Size([768, 2304])\n",
      "transformer.h.0.attn.c_attn.bias --- torch.Size([2304])\n",
      "transformer.h.0.attn.c_proj.weight --- torch.Size([768, 768])\n",
      "transformer.h.0.attn.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.0.ln_2.weight --- torch.Size([768])\n",
      "transformer.h.0.ln_2.bias --- torch.Size([768])\n",
      "transformer.h.0.mlp.c_fc.weight --- torch.Size([768, 3072])\n",
      "transformer.h.0.mlp.c_fc.bias --- torch.Size([3072])\n",
      "transformer.h.0.mlp.c_proj.weight --- torch.Size([3072, 768])\n",
      "transformer.h.0.mlp.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.1.ln_1.weight --- torch.Size([768])\n",
      "transformer.h.1.ln_1.bias --- torch.Size([768])\n",
      "transformer.h.1.attn.c_attn.weight --- torch.Size([768, 2304])\n",
      "transformer.h.1.attn.c_attn.bias --- torch.Size([2304])\n",
      "transformer.h.1.attn.c_proj.weight --- torch.Size([768, 768])\n",
      "transformer.h.1.attn.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.1.ln_2.weight --- torch.Size([768])\n",
      "transformer.h.1.ln_2.bias --- torch.Size([768])\n",
      "transformer.h.1.mlp.c_fc.weight --- torch.Size([768, 3072])\n",
      "transformer.h.1.mlp.c_fc.bias --- torch.Size([3072])\n",
      "transformer.h.1.mlp.c_proj.weight --- torch.Size([3072, 768])\n",
      "transformer.h.1.mlp.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.2.ln_1.weight --- torch.Size([768])\n",
      "transformer.h.2.ln_1.bias --- torch.Size([768])\n",
      "transformer.h.2.attn.c_attn.weight --- torch.Size([768, 2304])\n",
      "transformer.h.2.attn.c_attn.bias --- torch.Size([2304])\n",
      "transformer.h.2.attn.c_proj.weight --- torch.Size([768, 768])\n",
      "transformer.h.2.attn.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.2.ln_2.weight --- torch.Size([768])\n",
      "transformer.h.2.ln_2.bias --- torch.Size([768])\n",
      "transformer.h.2.mlp.c_fc.weight --- torch.Size([768, 3072])\n",
      "transformer.h.2.mlp.c_fc.bias --- torch.Size([3072])\n",
      "transformer.h.2.mlp.c_proj.weight --- torch.Size([3072, 768])\n",
      "transformer.h.2.mlp.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.3.ln_1.weight --- torch.Size([768])\n",
      "transformer.h.3.ln_1.bias --- torch.Size([768])\n",
      "transformer.h.3.attn.c_attn.weight --- torch.Size([768, 2304])\n",
      "transformer.h.3.attn.c_attn.bias --- torch.Size([2304])\n",
      "transformer.h.3.attn.c_proj.weight --- torch.Size([768, 768])\n",
      "transformer.h.3.attn.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.3.ln_2.weight --- torch.Size([768])\n",
      "transformer.h.3.ln_2.bias --- torch.Size([768])\n",
      "transformer.h.3.mlp.c_fc.weight --- torch.Size([768, 3072])\n",
      "transformer.h.3.mlp.c_fc.bias --- torch.Size([3072])\n",
      "transformer.h.3.mlp.c_proj.weight --- torch.Size([3072, 768])\n",
      "transformer.h.3.mlp.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.4.ln_1.weight --- torch.Size([768])\n",
      "transformer.h.4.ln_1.bias --- torch.Size([768])\n",
      "transformer.h.4.attn.c_attn.weight --- torch.Size([768, 2304])\n",
      "transformer.h.4.attn.c_attn.bias --- torch.Size([2304])\n",
      "transformer.h.4.attn.c_proj.weight --- torch.Size([768, 768])\n",
      "transformer.h.4.attn.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.4.ln_2.weight --- torch.Size([768])\n",
      "transformer.h.4.ln_2.bias --- torch.Size([768])\n",
      "transformer.h.4.mlp.c_fc.weight --- torch.Size([768, 3072])\n",
      "transformer.h.4.mlp.c_fc.bias --- torch.Size([3072])\n",
      "transformer.h.4.mlp.c_proj.weight --- torch.Size([3072, 768])\n",
      "transformer.h.4.mlp.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.5.ln_1.weight --- torch.Size([768])\n",
      "transformer.h.5.ln_1.bias --- torch.Size([768])\n",
      "transformer.h.5.attn.c_attn.weight --- torch.Size([768, 2304])\n",
      "transformer.h.5.attn.c_attn.bias --- torch.Size([2304])\n",
      "transformer.h.5.attn.c_proj.weight --- torch.Size([768, 768])\n",
      "transformer.h.5.attn.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.5.ln_2.weight --- torch.Size([768])\n",
      "transformer.h.5.ln_2.bias --- torch.Size([768])\n",
      "transformer.h.5.mlp.c_fc.weight --- torch.Size([768, 3072])\n",
      "transformer.h.5.mlp.c_fc.bias --- torch.Size([3072])\n",
      "transformer.h.5.mlp.c_proj.weight --- torch.Size([3072, 768])\n",
      "transformer.h.5.mlp.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.6.ln_1.weight --- torch.Size([768])\n",
      "transformer.h.6.ln_1.bias --- torch.Size([768])\n",
      "transformer.h.6.attn.c_attn.weight --- torch.Size([768, 2304])\n",
      "transformer.h.6.attn.c_attn.bias --- torch.Size([2304])\n",
      "transformer.h.6.attn.c_proj.weight --- torch.Size([768, 768])\n",
      "transformer.h.6.attn.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.6.ln_2.weight --- torch.Size([768])\n",
      "transformer.h.6.ln_2.bias --- torch.Size([768])\n",
      "transformer.h.6.mlp.c_fc.weight --- torch.Size([768, 3072])\n",
      "transformer.h.6.mlp.c_fc.bias --- torch.Size([3072])\n",
      "transformer.h.6.mlp.c_proj.weight --- torch.Size([3072, 768])\n",
      "transformer.h.6.mlp.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.7.ln_1.weight --- torch.Size([768])\n",
      "transformer.h.7.ln_1.bias --- torch.Size([768])\n",
      "transformer.h.7.attn.c_attn.weight --- torch.Size([768, 2304])\n",
      "transformer.h.7.attn.c_attn.bias --- torch.Size([2304])\n",
      "transformer.h.7.attn.c_proj.weight --- torch.Size([768, 768])\n",
      "transformer.h.7.attn.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.7.ln_2.weight --- torch.Size([768])\n",
      "transformer.h.7.ln_2.bias --- torch.Size([768])\n",
      "transformer.h.7.mlp.c_fc.weight --- torch.Size([768, 3072])\n",
      "transformer.h.7.mlp.c_fc.bias --- torch.Size([3072])\n",
      "transformer.h.7.mlp.c_proj.weight --- torch.Size([3072, 768])\n",
      "transformer.h.7.mlp.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.8.ln_1.weight --- torch.Size([768])\n",
      "transformer.h.8.ln_1.bias --- torch.Size([768])\n",
      "transformer.h.8.attn.c_attn.weight --- torch.Size([768, 2304])\n",
      "transformer.h.8.attn.c_attn.bias --- torch.Size([2304])\n",
      "transformer.h.8.attn.c_proj.weight --- torch.Size([768, 768])\n",
      "transformer.h.8.attn.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.8.ln_2.weight --- torch.Size([768])\n",
      "transformer.h.8.ln_2.bias --- torch.Size([768])\n",
      "transformer.h.8.mlp.c_fc.weight --- torch.Size([768, 3072])\n",
      "transformer.h.8.mlp.c_fc.bias --- torch.Size([3072])\n",
      "transformer.h.8.mlp.c_proj.weight --- torch.Size([3072, 768])\n",
      "transformer.h.8.mlp.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.9.ln_1.weight --- torch.Size([768])\n",
      "transformer.h.9.ln_1.bias --- torch.Size([768])\n",
      "transformer.h.9.attn.c_attn.weight --- torch.Size([768, 2304])\n",
      "transformer.h.9.attn.c_attn.bias --- torch.Size([2304])\n",
      "transformer.h.9.attn.c_proj.weight --- torch.Size([768, 768])\n",
      "transformer.h.9.attn.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.9.ln_2.weight --- torch.Size([768])\n",
      "transformer.h.9.ln_2.bias --- torch.Size([768])\n",
      "transformer.h.9.mlp.c_fc.weight --- torch.Size([768, 3072])\n",
      "transformer.h.9.mlp.c_fc.bias --- torch.Size([3072])\n",
      "transformer.h.9.mlp.c_proj.weight --- torch.Size([3072, 768])\n",
      "transformer.h.9.mlp.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.10.ln_1.weight --- torch.Size([768])\n",
      "transformer.h.10.ln_1.bias --- torch.Size([768])\n",
      "transformer.h.10.attn.c_attn.weight --- torch.Size([768, 2304])\n",
      "transformer.h.10.attn.c_attn.bias --- torch.Size([2304])\n",
      "transformer.h.10.attn.c_proj.weight --- torch.Size([768, 768])\n",
      "transformer.h.10.attn.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.10.ln_2.weight --- torch.Size([768])\n",
      "transformer.h.10.ln_2.bias --- torch.Size([768])\n",
      "transformer.h.10.mlp.c_fc.weight --- torch.Size([768, 3072])\n",
      "transformer.h.10.mlp.c_fc.bias --- torch.Size([3072])\n",
      "transformer.h.10.mlp.c_proj.weight --- torch.Size([3072, 768])\n",
      "transformer.h.10.mlp.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.11.ln_1.weight --- torch.Size([768])\n",
      "transformer.h.11.ln_1.bias --- torch.Size([768])\n",
      "transformer.h.11.attn.c_attn.weight --- torch.Size([768, 2304])\n",
      "transformer.h.11.attn.c_attn.bias --- torch.Size([2304])\n",
      "transformer.h.11.attn.c_proj.weight --- torch.Size([768, 768])\n",
      "transformer.h.11.attn.c_proj.bias --- torch.Size([768])\n",
      "transformer.h.11.ln_2.weight --- torch.Size([768])\n",
      "transformer.h.11.ln_2.bias --- torch.Size([768])\n",
      "transformer.h.11.mlp.c_fc.weight --- torch.Size([768, 3072])\n",
      "transformer.h.11.mlp.c_fc.bias --- torch.Size([3072])\n",
      "transformer.h.11.mlp.c_proj.weight --- torch.Size([3072, 768])\n",
      "transformer.h.11.mlp.c_proj.bias --- torch.Size([768])\n",
      "transformer.ln_f.weight --- torch.Size([768])\n",
      "transformer.ln_f.bias --- torch.Size([768])\n",
      "tot_numt_param:  125164032\n"
     ]
    }
   ],
   "source": [
    "print(model.config)\n",
    "tot_numt_param = 0\n",
    "for layer_name, params in model.named_parameters():\n",
    "    print(layer_name,'---', params.shape)\n",
    "    n_p = 1\n",
    "    for p in params.shape:\n",
    "        n_p *= p\n",
    "    tot_numt_param += n_p\n",
    "    \n",
    "print(\"tot_numt_param: \", tot_numt_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de48863",
   "metadata": {},
   "source": [
    "#### 데이터셋 불러오기 (SFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685e11a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "class SFT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        pattern_instruction = 'prompt'  # instruction\n",
    "        pattern_output = 'completion'  # response\n",
    "\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example)\n",
    "            sources.append(tmp)\n",
    "\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1fe24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0edcd268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : tensor([  739,   378,   378,   378, 14659, 13394, 37091, 10651,   383, 25841,\n",
      "         8006, 14914,   375,  7673, 20479,  8091, 22311,  9036, 30902, 13675,\n",
      "          375,   378,   378,   378, 41951,   454,  9549, 20549,   383,  8142,\n",
      "         7192, 14914,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
      "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
      "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
      "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
      "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
      "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n",
      "output: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
      "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
      "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
      "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
      "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
      "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SFT_dataset(data_path_1_SFT='/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl', tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "print('input : %s'%train_dataset.input_ids[0])\n",
    "print('output: %s'%train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14876b76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.</s>\n"
     ]
    }
   ],
   "source": [
    "# train_dataset.input_ids[0]를 디코딩해보세요.\n",
    "print(tokenizer.decode(train_dataset.input_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10763b39",
   "metadata": {},
   "source": [
    "#### 트레이너 세팅 (SFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5360a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_idx = 0\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/aiffel/aiffel/KoChatGPT/sft_ckpts\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,\n",
    "    fp16 = True,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db775e79",
   "metadata": {},
   "source": [
    "#### 훈련 (SFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aacf610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.172100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.510200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "# RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`\n",
    "model.save_pretrained('/aiffel/aiffel/KoChatGPT/output_1_SFT_{:03d}'.format(run_idx))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8654d871",
   "metadata": {},
   "source": [
    "[1500/1500 05:37, Epoch 1/1]\n",
    "Step\tTraining Loss\n",
    " 500\t2.984100\n",
    "1000\t2.776800\n",
    "1500\t2.687200\n",
    "\n",
    "[1500/1500 05:39, Epoch 1/1]\n",
    "Step\tTraining Loss\n",
    " 500\t2.007000\n",
    "1000\t2.172100\n",
    "1500\t2.510200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e3b9aa",
   "metadata": {},
   "source": [
    "#### 모델 출력 예제 (SFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7146c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 된 모델이 아니라 현제 로드된 모델 사용해보기\n",
    "# generator = pipeline('text-generation', model='/aiffel/KoChatGPT/output_1_SFT', tokenizer=tokenizer)\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a4bc4c4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'불고기용 고기는 불고기, 돼지고기, 소고기, 양고기 등 다양한 종류가 있습니다. 일반적으로 불고기용 고기의 경우, 불고기와 돼지고기를 함께 먹을 수 있는 경우가 많습니다. 따라서 불고기용은 불고기보다 비싸지만, 불고기는 불고기보다 더 맛있게 먹을 수 있습니다.\\n\\\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'리처드 닉슨은 46대 부통령을 수행한 년도가 없습니다. 따라서 정확한 답변을 제공할 수 없습니다. \"리처드 닉슨\"이 무엇을 의미하는지 더 자세한 정보를 제공해주시면 더 정확한 답변을 드릴 수 있습니다. 리처드 닉슨은 미국 역사상 가장 유명한 부통령 중 한 명입니다. 리처드 닉슨의\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어?\n",
      "\n",
      "### Response(응답):'시카고 오 헤어 국제공항은 미국 캘리포니아 주에 위치해 있습니다. Sicraelele International Airports 소속 항공사입니다. Sichelor International AI language model and Images of translation. Sichelle International information\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이므로 미세먼지 여부를 알 수 없습니다. 하지만, 미세먼지 농도는 보통 매우 높기 때문에 대기 질이 좋지 않을 것으로 예상됩니다. 따라서 외출 시 마스크를 착용하시는 것이 좋습니다.\\n\\n미세먼지 농도가 높아지면 건강에 해로울 수\n"
     ]
    }
   ],
   "source": [
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?',\n",
    "    \"\"\"\\\n",
    "    Q: 로저는 5개의 테니스 공이 있습니다. 그는 테니스 공이 들어간 두 개의 캔을 샀고, 각각의 캔에는 3개의 공이 들어있습니다. 이때 테니스 공의 총 개수는?\n",
    "    A: 로저는 5개의 공으로 시작했고, 2개의 캔에는 각각 3개의 공이 들어있으니 총 6개의 공이 있습니다. 그러므로 5 + 6 = 11 입니다.\n",
    "    Q: 카페에는 23개의 사과가 있습니다. 20개는 점심에 먹었했고, 6개를 추가로 샀습니다. 이때 사과의 총 개수는?\n",
    "    A:\"\"\",\n",
    "    \"\"\"\\\n",
    "    SYSTEM: 당신은 화장품회사의 고객관리부 팀장입니다.\n",
    "    Q: 스킨케어 브랜드와 가치를 소개하는 따뜻하고 친근한 신규 구독자 환영 이메일을 작성하세요.\n",
    "    A:\"\"\",\n",
    "    \"\"\"\\\n",
    "    아래 문맥에 따라 질문에 답하세요. 답변은 짧고 간결하게 작성하세요. 답변이 확실하지 않은 경우 \\\"답변이 확실하지 않음\\\"으로 응답하세요.\n",
    "    맥락: Teplizumab은 뉴저지의 제약 회사인 Ortho Pharmaceutical 제약에서 유래되었습니다. 거기에서 과학자들은 OKT3라는 이름의 초기 버전 항체를 개발했습니다. 원래 쥐로부터 유래된 이 분자는 T 세포의 표면에 결합하여 그들의 세포 죽음을 막을 수 있었습니다. 1986년에는 신장 이식 후 장기 거부반응을 예방하는 데 도움이 되도록 승인되어 인간이 사용하도록 허용된 최초의 치료 항체가 되었습니다.\n",
    "    질문: OKT3는 어디에서 유래되었나요?\n",
    "    답변:\"\"\",]\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39939188",
   "metadata": {},
   "source": [
    "### Instruction(명령어):\n",
    "불고기용 고기 한우에요?\n",
    "\n",
    "### Response(응답):'저는 인공지능 어시스턴트이기 때문에, 불고기용 고기의 종류에 대한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 쇠고기 한우는 다양한 종류가 있을 수 있습니다. 어떤 종류의 고기를 원하시는지 알려주시면 더 정확한 답변을 드릴 수 있을 것 같습니다. 감사합니다.\\n감사합니다.\n",
    "\n",
    "### Instruction(명령어):\n",
    "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
    "\n",
    "### Response(응답):'리처드 닉슨은 46대 부통령직을 수행했습니다.業)에 따르면, 리처드 닉슨은 42대 부통령직을 수행할 수 있었습니다.業)은 \"리처드 닉슨\"이라는 이름을 가지고 있습니다.業은 미국 역사상 가장 유명한 부통령 중 한 명입니다.業은 존 F. 케네디(John F.) 대통령이 재임\n",
    "\n",
    "### Instruction(명령어):\n",
    "시카고 오헤어 국제공항은 어디에 있어?\n",
    "\n",
    "### Response(응답):'시카고 오 헤어 국제공항은 미국 캘리포니아 주 로스앤젤레스에 위치해 있습니다. January Transaction, Justice Metropolis and Positive Language (JML)입니다. JML)은 항공 교통수단(Translation System)에서\n",
    "\n",
    "### Instruction(명령어):\n",
    "오늘 미세먼지 어때?\n",
    "\n",
    "### Response(응답):'저는 인공지능 챗봇이므로 미세먼지 예보를 직접 확인할 수는 없습니다. 하지만, 미세먼지 정보를 제공하는 웹사이트나 앱을 찾아보시면 도움이 될 수 있습니다.\\n\\n미세먼지 예보는 대기 중 미세먼지 농도를 측정해 볼 수 있는 프로그램입니다. 예를 들어,\n",
    "\n",
    "### Instruction(명령어):\n",
    "Q: 로저는 5개의 테니스 공이 있습니다. 그는 테니스 공이 들어간 두 개의 캔을 샀고, 각각의 캔에는 3개의 공이 들어있습니다. 이때 테니스 공의 총 개수는?\n",
    "A: 로저는 5개의 공으로 시작했고, 2개의 캔에는 각각 3개의 공이 들어있으니 총 6개의 공이 있습니다. 그러므로 5 + 6 = 11 입니다.\n",
    "Q: 카페에는 23개의 사과가 있습니다. 20개는 점심에 먹었했고, 6개를 추가로 샀습니다. 이때 사과의 총 개수는?\n",
    "A:\n",
    "\n",
    "### Response(응답):'죄송합니다, 저는 AI 어시스턴트로써 정확한 정보를 알 수 없습니다. 추가적인 정보를 제공해주시면 더 정확한 답변을 드릴 수 있을 것 같습니다!\\n\\n로저는 4개의 공으로 모두 6개의 공을 구입했습니다.)\\n->>>\n",
    "\n",
    "### Instruction(명령어):\n",
    "SYSTEM: 당신은 화장품회사의 고객관리부 팀장입니다.\n",
    "Q: 스킨케어 브랜드와 가치를 소개하는 따뜻하고 친근한 신규 구독자 환영 이메일을 작성하세요.\n",
    "A:\n",
    "\n",
    "### Response(응답):'저는 인공지능 어시스턴트이기 때문에 자연어 이해에는 한계가 있습니다. 하지만, SYSTE MOOD은 많은 사람들이 함께하는 즐거운 경험을 제공하기 위해 노력하고 있습니다.\\n\\n감사합니다. so me to complete you like the translation.\n",
    "\n",
    "### Instruction(명령어):\n",
    "아래 문맥에 따라 질문에 답하세요. 답변은 짧고 간결하게 작성하세요. 답변이 확실하지 않은 경우 \"답변이 확실하지 않음\"으로 응답하세요.\n",
    "맥락: Teplizumab은 뉴저지의 제약 회사인 Ortho Pharmaceutical 제약에서 유래되었습니다. 거기에서 과학자들은 OKT3라는 이름의 초기 버전 항체를 개발했습니다. 원래 쥐로부터 유래된 이 분자는 T 세포의 표면에 결합하여 그들의 세포 죽음을 막을 수 있었습니다. 1986년에는 신장 이식 후 장기 거부반응을 예방하는 데 도움이 되도록 승인되어 인간이 사용하도록 허용된 최초의 치료 항체가 되었습니다.\n",
    "질문: OKT3는 어디에서 유래되었나요?\n",
    "답변:\n",
    "\n",
    "### Response(응답):{'OKT3\\n\"It\", 'token': \"It's been about the sense of precision model and close.\" \"It was there an AI language for transl"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a47f5ae",
   "metadata": {},
   "source": [
    "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
    "| N/A   68C    P0              32W /  70W |  13117MiB / 15360MiB |      0%      Default |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea9cadb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98bb00cb",
   "metadata": {},
   "source": [
    "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
    "| N/A   67C    P0              32W /  70W |   3239MiB / 15360MiB |      0%      Default |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c762bf36",
   "metadata": {},
   "source": [
    "### 리워드 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e27085d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "# 아래 모듈은 홈 디렉토리에서 임포트 해야한다\n",
    "cwd = os.getcwd()\n",
    "os.chdir(os.getenv(\"HOME\"))\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "os.chdir(cwd)\n",
    "\n",
    "from transformers import AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6796e5",
   "metadata": {},
   "source": [
    "#### 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01bea048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f2e80c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "# 아래 명령어의 옵션이 주는 효과?; lora_rank=0 이건 효과가 있는 것인가?\n",
    "with NaiveStrategy().model_init_context():\n",
    "    model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ea902",
   "metadata": {},
   "source": [
    "#### 입력 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cefe4e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9b06991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 10220\n",
      "after  data num: 30660\n",
      "data example: \n",
      "{'prompt': '애플은 리사를 어떻게 처리했어', 'chosen': '애플이 누구인지 명확히 알 수 없어서, 리사가 누구인지와 어떤 상황에서 처리되었는지에 대한 추가적인 정보가 필요합니다. 따라서, 보다 정확한 답변을 제공할 수 없습니다.', 'rejected': '애플은 리사를 위해 고객 서비스 부서에서 고객 다양한 컴퓨터 관련 문제에 대해 응답하는 데 필요한 모든 지원을 제공했습니다. 사용자가 하드웨어 문제를 경험할 때, 전문가들은 필요한 수리(수리, 추가 부품 제공, 소프트웨어 업그레이드 등)을 제공해 드릴 수 있습니다. 또한, 사용자가 사용 방법 문제나 기타 문제를 경험할 때, 대화 상대로 사용자를 지원할 수 있는 전문 고객 서비스 직원들이 사용자에게 상담하고 도움을 주는 데 도움이 될 수 있는 정보를 제공합니다. 또한, 인터넷에서 제공되는 정보를 통해 문제를 해결하거나 고객 서비스 웹 사이트를 통해 자신의 문제를 진단할 수 있도록 하는 등 다양한 방법으로 리사를 처리해 왔습니다.'}\n"
     ]
    }
   ],
   "source": [
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92dfa8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '해마가 위치 정보를 파악하는 역할을 하는 것은 해마에 무엇이 존재하기 때문인가?', 'chosen': '해마는 해마 측근 관련 뉴런이 존재하여 위치 정보를 파악하고 기억하는 역할을 합니다. 해마는 고양이, 쥐, 사람 등 다양한 동물들의 뇌에서 발견되며, 오랜 시간 동안 연구된 결과, 해마는 공간 정보 처리를 담당하는 뇌의 중요한 영역 중 하나로 알려져 있습니다.', 'rejected': '위치 정보는 국가들의 페이지를 통한 국가들의 페이지를 통한 국가들의 페이지 국가들의 페이지 국가들의 페이지 국가들의 페이지 국가들의 페이지 국가들의 페이지 국가들의 페이지 국가들의 페이지 국가들의 페이지 국가들의 페이지 국가들의'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(230319)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94250dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_data_ranking2chosen:  30660\n",
      "train_data:  1000\n",
      "eval_data:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1286.44it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 1091.50it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(\"total_data_ranking2chosen: \", len(total_data_ranking2chosen))\n",
    "print(\"train_data: \", len(train_data))\n",
    "print(\"eval_data: \", len(eval_data))\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d402b41a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "## prompt ##\n",
      "흑고래의 무게는 어느 정도야\n",
      "----------------------------------------------------------------------\n",
      "## chosen ##\n",
      "흑고래의 평균 몸무게는 약 25~40톤 정도이지만, 최대 몸무게는 50톤 이상에 이를 수 있습니다.\n",
      "----------------------------------------------------------------------\n",
      "## rejected ##\n",
      "흑고래의 무게는 매우 다양하게 달라집니다. 약 200kg에서 10톤까지 달라질 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print('-'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('-'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('-'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddf70b1",
   "metadata": {},
   "source": [
    "#### 트레이너 구성 및 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fe9f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b03b79bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA 옵션의 의미?\n",
    "# trainer.fit(use_lora=0)\n",
    "\n",
    "# 왜 진행상황 막대가 제대로 출력되지 않을까?\n",
    "# model.save_pretrained('aiffel/KoChatGPT/output_2_RM')\n",
    "model.save_pretrained('/aiffel/aiffel/KoChatGPT/output_2_RM_{:03d}'.format(run_idx))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc4372e0",
   "metadata": {},
   "source": [
    "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
    "| N/A   69C    P0              32W /  70W |  10141MiB / 15360MiB |      0%      Default |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d8817d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 똥멍청이 입니다\n",
      "reward score: 0.3\n"
     ]
    }
   ],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "input_text = '인공지능은 똥멍청이 입니다'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8dd5540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.\n",
      "reward score: -0.4\n"
     ]
    }
   ],
   "source": [
    "input_text = '인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "244674dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\n",
      "reward score: -0.5\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6c9a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\n",
      "reward score: -0.4\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ab7aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719df16a",
   "metadata": {},
   "source": [
    "### PPO 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0136bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "\n",
    "# 아래 Strategy 말고 다른 것이 있을까?\n",
    "# from chatgpt.trainer.strategies import NaiveStrategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fda1de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='/aiffel/aiffel/KoChatGPT/output_1_SFT_{:03d}'.format(0),\n",
    "                                     lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='/aiffel/aiffel/KoChatGPT/output_2_RM_{:03d}'.format(0),\n",
    "                                       lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c41ee03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "beccabe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af49247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1baf04dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[47311, 10448, 19008,  9792, 11780, 11308, 30190, 10929, 11849, 21663,\n",
      "         44389,  9574, 13799,   458, 14308, 12778, 22469, 20938, 44696,   458,\n",
      "         13799,   458, 14308, 12778, 11756, 18944,   389]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "209df046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35f0fddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf015184",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2465f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.94s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.0016]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.77it/s, actor_loss=0, critic_loss=0.0016]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.77it/s, actor_loss=0, critic_loss=0.138] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s, actor_loss=0, critic_loss=0.138]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s, actor_loss=0, critic_loss=0.0099]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s, actor_loss=0, critic_loss=0.0099]\u001b[A\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:19<00:00,  6.46s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.97s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.14, critic_loss=0.026]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.80it/s, actor_loss=-.14, critic_loss=0.026]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.80it/s, actor_loss=-.138, critic_loss=0.0661]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s, actor_loss=-.138, critic_loss=0.0661]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s, actor_loss=-.145, critic_loss=0.0711]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.81it/s, actor_loss=-.145, critic_loss=0.0711]\u001b[A\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:19<00:00,  6.55s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.33s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.125, critic_loss=0.0151]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.75it/s, actor_loss=-.125, critic_loss=0.0151]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.75it/s, actor_loss=-.123, critic_loss=0.0016]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.75it/s, actor_loss=-.123, critic_loss=0.0016]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.75it/s, actor_loss=-.131, critic_loss=0.0103]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.76it/s, actor_loss=-.131, critic_loss=0.0103]\u001b[A\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:20<00:00,  6.94s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:13<00:06,  6.65s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.21, critic_loss=0.043]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.75it/s, actor_loss=0.21, critic_loss=0.043]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.75it/s, actor_loss=0.201, critic_loss=0.0343]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s, actor_loss=0.201, critic_loss=0.0343]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s, actor_loss=0.201, critic_loss=0.0232]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.76it/s, actor_loss=0.201, critic_loss=0.0232]\u001b[A\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:21<00:00,  7.18s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.35s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0682, critic_loss=0.00558]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.79it/s, actor_loss=0.0682, critic_loss=0.00558]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.79it/s, actor_loss=0.0484, critic_loss=0.00228]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.79it/s, actor_loss=0.0484, critic_loss=0.00228]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.79it/s, actor_loss=0.0975, critic_loss=0.00445]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s, actor_loss=0.0975, critic_loss=0.00445]\u001b[A\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:20<00:00,  6.94s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.30s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.12, critic_loss=0.0206]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.78it/s, actor_loss=-.12, critic_loss=0.0206]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.78it/s, actor_loss=-.117, critic_loss=0.0243]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s, actor_loss=-.117, critic_loss=0.0243]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s, actor_loss=-.125, critic_loss=0.0123]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s, actor_loss=-.125, critic_loss=0.0123]\u001b[A\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:20<00:00,  6.91s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.38s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0441, critic_loss=0.0023]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.78it/s, actor_loss=-.0441, critic_loss=0.0023]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.78it/s, actor_loss=-.0484, critic_loss=0.000622]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.77it/s, actor_loss=-.0484, critic_loss=0.000622]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.77it/s, actor_loss=-.0595, critic_loss=0.00336] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.77it/s, actor_loss=-.0595, critic_loss=0.00336]\u001b[A\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:20<00:00,  6.96s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.38s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0949, critic_loss=0.0109]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.78it/s, actor_loss=0.0949, critic_loss=0.0109]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.78it/s, actor_loss=0.112, critic_loss=0.0145] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s, actor_loss=0.112, critic_loss=0.0145]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s, actor_loss=0.0752, critic_loss=0.0029]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.77it/s, actor_loss=0.0752, critic_loss=0.0029]\u001b[A\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:20<00:00,  6.95s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.69s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0518, critic_loss=0.00472]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.78it/s, actor_loss=0.0518, critic_loss=0.00472]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.78it/s, actor_loss=0.0467, critic_loss=0.00215]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.77it/s, actor_loss=0.0467, critic_loss=0.00215]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.77it/s, actor_loss=0.0526, critic_loss=0.00318]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.77it/s, actor_loss=0.0526, critic_loss=0.00318]\u001b[A\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:19<00:00,  6.53s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.37s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0454, critic_loss=0.00422]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.78it/s, actor_loss=-.0454, critic_loss=0.00422]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.78it/s, actor_loss=-.0701, critic_loss=0.00802]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.79it/s, actor_loss=-.0701, critic_loss=0.00802]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.79it/s, actor_loss=-.0558, critic_loss=0.00494]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s, actor_loss=-.0558, critic_loss=0.00494]\u001b[A\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:19<00:00,  6.37s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "# model.save_pretrained('aiffel/KoChatGPT/output_3_PPO')\n",
    "model.save_pretrained('/aiffel/aiffel/KoChatGPT/output_3_PPO_{:03d}'.format(run_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7831654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'네, 불고기를 파는 상점에서 불고기용 고기인 '불고기용 고기(bangtwoak)'를 판매하는 경우가 많습니다. 불고기용 고기는 주로 식초, 소스, 된장, 참기름 등 다양한 재료가 사용되며, 일반적으로 불고기 양념에 불고기를 넣은 소스, 무 등을 넣어서 만든 양념고기와 된장으로도 많이 사용되는 것이 특징입니다. 高木洞山 (불고기를 판매하는 상점의 이름)\\n\\n불고기용 고기는 주로 육류, 고기, 소스 등으로 조리됩니다. 불고기용 고기는 일반적으로 돼지고기를 요리하여 제조됩니다. 불고기의 기본 재료 중 하나로 알려진 것으로 알려져 있으며, 불고기용 고기는 고기를 구워내는데 필수적인 것으로 알려져 있습니다.神陽 洪積土 (불고기용의 고기)\\n\\n불고기용은 일반적으로 고기 한우(불고기용 고기를 썰어내 양념한 고기를 사용하여 만들어집니다. 불고기용은 주로 육류, 소, 양 등으로 제조됩니다. 불고기용은 일반적으로 육류, 고기, 생선류 등으로 조리됩니다. 洪積土 \n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'리처드 닉슨은 43대 부통령직을 수행한 년도는 정확히 밝혀지지 않았습니다. 承法\\n tissue of v\\n- \\n- 닉슨이 47대 부통령직을 맡은 정확한 정보는 알려지지 않았습니다. tion\\n- 닉슨은 34대 부통령직을 맡은 정확한 연도는 알려지지 않았습니다. \\n- 닉슨은 39대 부통령직을 맡았던 정확한 연도는 공개되지 않았습니다. \\n- 닉슨은 36대 부통령직을 맡았던 정확한 연도는 알려지지 않았습니다. \\n- 닉슨은 39대 부통령직을 맡은 정확한 연도는 알려지지 않았습니다. \\n\\n리처드 닉슨은 41대 부통령직을 맡았던 정확한 연도는 알려져 있지 않습니다. tion\\n- 닉슨은 41대 부통령직을 수행한 구체적인 연도는 밝혀지지 않았지만, 닉슨은 39대 부통령직에 있었던 정확한 연도는 아직 발표되지 않았습니다. \\n- 닉슨은 48대 부통령직을 맡은 정확한 연도는 알려지지 않았습니다. tion\\n- 닉슨은 38대 부통령직을 맡은 정확한 연도는 알려지지 않았습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):'시카고 오헤어 국제공항은 미국 캘리포니아주 어바인에 위치해 있습니다. éiiira Jealter Publica (뉴욕시) Can Young\\'t are repairdy with clarify or élie\\e\\'embau- \\e\\'re-air-to out and had and my\\'\\n\\n시카고 오헤어 국제공항은 시카고에서 매우 인기있는 지역 중 하나입니다. 다양한 노선이 운영되고 있으며, 일부 도시는 대중적으로 잘 알려져 있습니다. to explry districk émes ébiy (코네티컷주) pandhed and important emvies socrates (사우스) éiiira Jealter \\n\\n- \\n\\n- \\n- \\n- \\n- \\n- \\n- \\n- \\n- \n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇입니다. 오늘 미세먼지 때문에 고요하면 좀 걱정되는 건가요? 하지만 이 말씀이 무슨 말씀인지 알려 주시면 제가 도움이 될 것 같습니다. 감사합니다. allowever, 'token': 139} 'token': 155} 'token': 144} 'token': 138} 'token': 156} 'token': 159} 'token': 162} 'token': 162} 'token': 184} 'token': 174} 'token': 174} 'token': 184} 'token': 187} 'token': 175} 'token': 141} 'token': 186} 'token': 182} 'token': 139} 'token': 184}\n",
      "\n",
      "### Instruction(명령어):\n",
      "Q: 로저는 5개의 테니스 공이 있습니다. 그는 테니스 공이 들어간 두 개의 캔을 샀고, 각각의 캔에는 3개의 공이 들어있습니다. 이때 테니스 공의 총 개수는?\n",
      "A: 로저는 5개의 공으로 시작했고, 2개의 캔에는 각각 3개의 공이 들어있으니 총 6개의 공이 있습니다. 그러므로 5 + 6 = 11 입니다.\n",
      "Q: 카페에는 23개의 사과가 있습니다. 20개는 점심에 먹었했고, 6개를 추가로 샀습니다. 이때 사과의 총 개수는?\n",
      "A:\n",
      "\n",
      "### Response(응답):'One it! Chrosse Wills\" The white query language bring\", 'token': 77} 'Make wave incush-life': \"로저는 4개의 공으로 총 8개의 공을 샀습니다.\", 'token': 80} 'Hibd': 85} 'token': 69} 'token': \"로저는 2개의 공으로 총 4개의 공을 샀습니다. chrosse': \"로저는 하나의 공으로 총 4개의 공을 샀습니다. 'tok\n",
      "\n",
      "### Instruction(명령어):\n",
      "SYSTEM: 당신은 화장품회사의 고객관리부 팀장입니다.\n",
      "Q: 스킨케어 브랜드와 가치를 소개하는 따뜻하고 친근한 신규 구독자 환영 이메일을 작성하세요.\n",
      "A:\n",
      "\n",
      "### Response(응답):'죄송합니다. 제가 SYSTEM입니다. 브랜드, 제품, 서비스, 광고 등 다양한 정보를 제공해주시면 답변드릴 수 있습니다. SYSTEM: SSGIN, SWM, P&B 등의 브랜드를 보유한 기업입니다. 이 곳의 고객관리부 팀장들은 고객들로부터 사랑받는 브랜드 중 하나입니다. SSGIN: \"SYSTEM: 당신은 화장제품의 브랜드와 가치를 소개하는 친근한 신규 구독자 환영 이메일을 작성하셨군요. 이제부터 SYSTEM이 출시될 때 까지 고객들의 사랑과 만족을 보답할 것을 약속합니다. Natural Kit은 회사의 고객 서비스에 대한 정보와 이미지를 알려드리는 좋은 홍보가 됩니다. SYSTEM:\\n\\n\"SSSYSTEM: 당신의 화장품 브랜드는 사랑이다.\", '\n",
      "\n",
      "### Instruction(명령어):\n",
      "아래 문맥에 따라 질문에 답하세요. 답변은 짧고 간결하게 작성하세요. 답변이 확실하지 않은 경우 \"답변이 확실하지 않음\"으로 응답하세요.\n",
      "맥락: Teplizumab은 뉴저지의 제약 회사인 Ortho Pharmaceutical 제약에서 유래되었습니다. 거기에서 과학자들은 OKT3라는 이름의 초기 버전 항체를 개발했습니다. 원래 쥐로부터 유래된 이 분자는 T 세포의 표면에 결합하여 그들의 세포 죽음을 막을 수 있었습니다. 1986년에는 신장 이식 후 장기 거부반응을 예방하는 데 도움이 되도록 승인되어 인간이 사용하도록 허용된 최초의 치료 항체가 되었습니다.\n",
      "질문: OKT3는 어디에서 유래되었나요?\n",
      "답변:\n",
      "\n",
      "### Response(응답):'저는 답변을 정확하게 이해하고 이해하기 때문에, 맥락만으로는 정확한 답을 내리기는 어렵습니다. 하지만, 문맥에 따라 여러 가지 문제가 있을 수 있습니다. 양해 부탁드립니다. English:\\n\\n맥락만으로 문맥에 따라 답변됩니다. 감사합니다. English:\\n\\nOKT-3의 경우 의료계에서 OKT-3라는 이름으로 최초 버전인 것은 OKT-3라는 버전입니다. N\n"
     ]
    }
   ],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?',\n",
    "    \"\"\"\\\n",
    "    Q: 로저는 5개의 테니스 공이 있습니다. 그는 테니스 공이 들어간 두 개의 캔을 샀고, 각각의 캔에는 3개의 공이 들어있습니다. 이때 테니스 공의 총 개수는?\n",
    "    A: 로저는 5개의 공으로 시작했고, 2개의 캔에는 각각 3개의 공이 들어있으니 총 6개의 공이 있습니다. 그러므로 5 + 6 = 11 입니다.\n",
    "    Q: 카페에는 23개의 사과가 있습니다. 20개는 점심에 먹었했고, 6개를 추가로 샀습니다. 이때 사과의 총 개수는?\n",
    "    A:\"\"\",\n",
    "    \"\"\"\\\n",
    "    SYSTEM: 당신은 화장품회사의 고객관리부 팀장입니다.\n",
    "    Q: 스킨케어 브랜드와 가치를 소개하는 따뜻하고 친근한 신규 구독자 환영 이메일을 작성하세요.\n",
    "    A:\"\"\",\n",
    "    \"\"\"\\\n",
    "    아래 문맥에 따라 질문에 답하세요. 답변은 짧고 간결하게 작성하세요. 답변이 확실하지 않은 경우 \\\"답변이 확실하지 않음\\\"으로 응답하세요.\n",
    "    맥락: Teplizumab은 뉴저지의 제약 회사인 Ortho Pharmaceutical 제약에서 유래되었습니다. 거기에서 과학자들은 OKT3라는 이름의 초기 버전 항체를 개발했습니다. 원래 쥐로부터 유래된 이 분자는 T 세포의 표면에 결합하여 그들의 세포 죽음을 막을 수 있었습니다. 1986년에는 신장 이식 후 장기 거부반응을 예방하는 데 도움이 되도록 승인되어 인간이 사용하도록 허용된 최초의 치료 항체가 되었습니다.\n",
    "    질문: OKT3는 어디에서 유래되었나요?\n",
    "    답변:\"\"\",]\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b29ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bab82c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5de85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4cdf3a",
   "metadata": {},
   "source": [
    "### Back-bone 모델 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5026d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import logging\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from datasets import load_dataset\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bacddb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model_name = \"skt/kogpt2-base-v2\"\n",
    "model_name = \"skt/ko-gpt-trinity-1.2B-v0.5\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36103f0",
   "metadata": {},
   "source": [
    "#### 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b308c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoConfig\n",
    "ko_gpt_config = AutoConfig.from_pretrained(model_name,\n",
    "#                                            ignore_mismatched_sizes=True,\n",
    "# **{\"vocab_size\": 32000,\n",
    "#   \"ignore_mismatched_sizes\" :True  }\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18cfaf9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, config=ko_gpt_config)#.to(device)\n",
    "# model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c037babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Config {\n",
      "  \"_name_or_path\": \"skt/ko-gpt-trinity-1.2B-v0.5\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 8,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 1920,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": 7680,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 8,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.28.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "transformer.wte.weight --- torch.Size([51200, 1920])\n",
      "transformer.wpe.weight --- torch.Size([1024, 1920])\n",
      "transformer.h.0.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.0.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.0.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.0.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.0.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.0.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.0.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.0.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.0.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.0.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.0.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.0.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.1.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.1.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.1.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.1.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.1.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.1.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.1.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.1.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.1.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.1.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.1.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.1.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.2.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.2.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.2.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.2.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.2.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.2.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.2.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.2.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.2.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.2.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.2.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.2.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.3.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.3.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.3.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.3.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.3.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.3.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.3.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.3.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.3.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.3.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.3.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.3.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.4.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.4.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.4.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.4.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.4.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.4.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.4.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.4.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.4.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.4.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.4.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.4.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.5.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.5.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.5.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.5.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.5.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.5.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.5.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.5.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.5.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.5.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.5.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.5.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.6.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.6.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.6.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.6.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.6.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.6.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.6.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.6.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.6.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.6.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.6.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.6.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.7.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.7.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.7.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.7.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.7.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.7.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.7.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.7.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.7.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.7.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.7.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.7.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.8.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.8.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.8.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.8.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.8.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.8.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.8.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.8.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.8.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.8.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.8.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.8.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.9.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.9.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.9.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.9.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.9.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.9.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.9.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.9.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.9.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.9.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.9.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.9.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.10.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.10.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.10.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.10.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.10.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.10.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.10.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.10.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.10.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.10.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.10.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.10.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.11.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.11.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.11.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.11.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.11.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.11.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.11.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.11.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.11.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.11.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.11.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.11.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.12.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.12.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.12.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.12.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.12.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.12.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.12.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.12.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.12.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.12.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.12.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.12.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.13.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.13.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.13.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.13.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.13.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.13.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.13.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.13.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.13.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.13.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.13.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.13.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.14.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.14.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.14.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.14.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.14.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.14.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.14.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.14.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.14.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.14.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.14.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.14.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.15.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.15.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.15.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.15.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.15.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.15.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.15.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.15.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.15.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.15.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.15.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.15.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.16.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.16.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.16.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.16.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.16.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.16.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.16.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.16.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.16.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.16.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.16.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.16.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.17.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.17.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.17.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.17.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.17.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.17.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.17.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.17.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.17.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.17.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.17.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.17.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.18.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.18.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.18.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.18.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.18.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.18.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.18.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.18.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.18.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.18.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.18.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.18.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.19.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.19.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.19.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.19.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.19.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.19.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.19.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.19.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.19.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.19.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.19.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.19.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.20.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.20.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.20.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.20.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.20.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.20.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.20.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.20.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.20.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.20.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.20.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.20.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.21.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.21.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.21.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.21.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.21.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.21.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.21.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.21.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.21.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.21.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.21.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.21.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.22.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.22.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.22.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.22.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.22.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.22.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.22.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.22.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.22.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.22.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.22.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.22.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.23.ln_1.weight --- torch.Size([1920])\n",
      "transformer.h.23.ln_1.bias --- torch.Size([1920])\n",
      "transformer.h.23.attn.c_attn.weight --- torch.Size([1920, 5760])\n",
      "transformer.h.23.attn.c_attn.bias --- torch.Size([5760])\n",
      "transformer.h.23.attn.c_proj.weight --- torch.Size([1920, 1920])\n",
      "transformer.h.23.attn.c_proj.bias --- torch.Size([1920])\n",
      "transformer.h.23.ln_2.weight --- torch.Size([1920])\n",
      "transformer.h.23.ln_2.bias --- torch.Size([1920])\n",
      "transformer.h.23.mlp.c_fc.weight --- torch.Size([1920, 7680])\n",
      "transformer.h.23.mlp.c_fc.bias --- torch.Size([7680])\n",
      "transformer.h.23.mlp.c_proj.weight --- torch.Size([7680, 1920])\n",
      "transformer.h.23.mlp.c_proj.bias --- torch.Size([1920])\n",
      "transformer.ln_f.weight --- torch.Size([1920])\n",
      "transformer.ln_f.bias --- torch.Size([1920])\n",
      "tot_numt_param:  1162556160\n"
     ]
    }
   ],
   "source": [
    "print(model.config)\n",
    "tot_numt_param = 0\n",
    "for layer_name, params in model.named_parameters():\n",
    "    print(layer_name,'---', params.shape)\n",
    "    n_p = 1\n",
    "    for p in params.shape:\n",
    "        n_p *= p\n",
    "    tot_numt_param += n_p\n",
    "    \n",
    "print(\"tot_numt_param: \", tot_numt_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db22427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    # 특수 토큰들을 '</s>'로 통일한 이유가 있는 걸까?\n",
    "    # 설정을 바꾸면 vocab크기가 달라져 오류 발생; CUBLAS_STATUS_NOT_INITIALIZED\n",
    "    # model_name, bos_token='<bos>', eos_token='<eos>', unk_token='<unk>', pad_token='<pad>',\n",
    "    model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=128,\n",
    "#     **{\"vocab_size\": 32000}\n",
    ")\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a69d6e7",
   "metadata": {},
   "source": [
    "#### 데이터셋 불러오기 (SFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4cb152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "class SFT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        pattern_instruction = 'prompt'  # instruction\n",
    "        pattern_output = 'completion'  # response\n",
    "\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example)\n",
    "            sources.append(tmp)\n",
    "\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc7def",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SFT_dataset(data_path_1_SFT='/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl', tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "print('input : %s'%train_dataset.input_ids[0])\n",
    "print('output: %s'%train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaffc91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_dataset.input_ids[0]를 디코딩해보세요.\n",
    "print(tokenizer.decode(train_dataset.input_ids[0]))\n",
    "len(train_dataset.input_ids[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb043edd",
   "metadata": {},
   "source": [
    "max_length=128"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ff1e0b0",
   "metadata": {},
   "source": [
    "input_txt = \"\"\"\n",
    "Q: 로저는 5개의 테니스 공이 있습니다. 그는 테니스 공이 들어간 두 개의 캔을 샀고, 각각의 캔에는 3개의 공이 들어있습니다. 이때 테니스 공의 총 개수는?\n",
    "A: 로저는 5개의 공으로 시작했고, 2개의 캔에는 각각 3개의 공이 들어있으니 총 6개의 공이 있습니다. 그러므로 5 + 6 = 11 입니다.\n",
    "Q: 카페에는 23개의 사과가 있습니다. 20개는 점심에 먹었했고, 6개를 추가로 샀습니다. 이때 사과의 총 개수는?\n",
    "\"\"\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=7,\n",
    "                        no_repeat_ngram_size=2, do_sample=True, top_p=0.90)\n",
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "888ea67a",
   "metadata": {},
   "source": [
    "input_txt = \"\"\"\\\n",
    "SYSTEM: 당신은 화장품회사의 고객관리부 팀장입니다.\n",
    "Q: 스킨케어 브랜드와 가치를 소개하는 따뜻하고 친근한 신규 구독자 환영 이메일을 작성하세요.\n",
    "A:\"\"\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_beam = model.generate(input_ids, max_length=256, num_beams=7,\n",
    "                        no_repeat_ngram_size=2, do_sample=True, top_p=0.90)\n",
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c445b215",
   "metadata": {},
   "source": [
    "input_txt = \"\"\"\\\n",
    "아래 문맥에 따라 질문에 답하세요. 답변은 짧고 간결하게 작성하세요. 답변이 확실하지 않은 경우 \\\"답변이 확실하지 않음\\\"으로 응답하세요.\n",
    "맥락: Teplizumab은 뉴저지의 제약 회사인 Ortho Pharmaceutical 제약에서 유래되었습니다. 거기에서 과학자들은 OKT3라는 이름의 초기 버전 항체를 개발했습니다. 원래 쥐로부터 유래된 이 분자는 T 세포의 표면에 결합하여 그들의 세포 죽음을 막을 수 있었습니다. 1986년에는 신장 이식 후 장기 거부반응을 예방하는 데 도움이 되도록 승인되어 인간이 사용하도록 허용된 최초의 치료 항체가 되었습니다.\n",
    "질문: OKT3는 어디에서 유래되었나요?\n",
    "답변:\"\"\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_beam = model.generate(input_ids, max_length=512, num_beams=7,\n",
    "                        no_repeat_ngram_size=2, do_sample=True, top_p=0.90)\n",
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e171f87c",
   "metadata": {},
   "source": [
    "#### 트레이너 세팅 (SFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ad212",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_idx = 1\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/aiffel/aiffel/KoChatGPT/sft_ckpts_{:03d}\".format(run_idx),\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,\n",
    "    fp16 = True,\n",
    "    group_by_length = True, # Bucketing을 적용\n",
    "    abc\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e75a7",
   "metadata": {},
   "source": [
    "#### 훈련 (SFT)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bbc968ae",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f78476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "# RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`\n",
    "model.save_pretrained('/aiffel/aiffel/KoChatGPT/output_1_SFT_{:03d}'.format(run_idx))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c268a79",
   "metadata": {},
   "source": [
    "[1500/1500 05:37, Epoch 1/1]\n",
    "Step\tTraining Loss\n",
    " 500\t2.984100\n",
    "1000\t2.776800\n",
    "1500\t2.687200\n",
    "\n",
    "[1500/1500 05:39, Epoch 1/1]\n",
    "Step\tTraining Loss\n",
    " 500\t2.007000\n",
    "1000\t2.172100\n",
    "1500\t2.510200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc1a2f",
   "metadata": {},
   "source": [
    "#### 모델 출력 예제 (SFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bfcee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 된 모델이 아니라 현제 로드된 모델 사용해보기\n",
    "# generator = pipeline('text-generation', model='/aiffel/KoChatGPT/output_1_SFT', tokenizer=tokenizer)\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcc24e2c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'불고기용 고기는 불고기, 돼지고기, 소고기, 양고기 등 다양한 종류가 있습니다. 일반적으로 불고기용 고기의 경우, 불고기와 돼지고기를 함께 먹을 수 있는 경우가 많습니다. 따라서 불고기용은 불고기보다 비싸지만, 불고기는 불고기보다 더 맛있게 먹을 수 있습니다.\\n\\\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'리처드 닉슨은 46대 부통령을 수행한 년도가 없습니다. 따라서 정확한 답변을 제공할 수 없습니다. \"리처드 닉슨\"이 무엇을 의미하는지 더 자세한 정보를 제공해주시면 더 정확한 답변을 드릴 수 있습니다. 리처드 닉슨은 미국 역사상 가장 유명한 부통령 중 한 명입니다. 리처드 닉슨의\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어?\n",
      "\n",
      "### Response(응답):'시카고 오 헤어 국제공항은 미국 캘리포니아 주에 위치해 있습니다. Sicraelele International Airports 소속 항공사입니다. Sichelor International AI language model and Images of translation. Sichelle International information\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이므로 미세먼지 여부를 알 수 없습니다. 하지만, 미세먼지 농도는 보통 매우 높기 때문에 대기 질이 좋지 않을 것으로 예상됩니다. 따라서 외출 시 마스크를 착용하시는 것이 좋습니다.\\n\\n미세먼지 농도가 높아지면 건강에 해로울 수\n"
     ]
    }
   ],
   "source": [
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?',\n",
    "    \"\"\"\\\n",
    "    Q: 로저는 5개의 테니스 공이 있습니다. 그는 테니스 공이 들어간 두 개의 캔을 샀고, 각각의 캔에는 3개의 공이 들어있습니다. 이때 테니스 공의 총 개수는?\n",
    "    A: 로저는 5개의 공으로 시작했고, 2개의 캔에는 각각 3개의 공이 들어있으니 총 6개의 공이 있습니다. 그러므로 5 + 6 = 11 입니다.\n",
    "    Q: 카페에는 23개의 사과가 있습니다. 20개는 점심에 먹었했고, 6개를 추가로 샀습니다. 이때 사과의 총 개수는?\n",
    "    A:\"\"\",\n",
    "    \"\"\"\\\n",
    "    SYSTEM: 당신은 화장품회사의 고객관리부 팀장입니다.\n",
    "    Q: 스킨케어 브랜드와 가치를 소개하는 따뜻하고 친근한 신규 구독자 환영 이메일을 작성하세요.\n",
    "    A:\"\"\",\n",
    "    \"\"\"\\\n",
    "    아래 문맥에 따라 질문에 답하세요. 답변은 짧고 간결하게 작성하세요. 답변이 확실하지 않은 경우 \\\"답변이 확실하지 않음\\\"으로 응답하세요.\n",
    "    맥락: Teplizumab은 뉴저지의 제약 회사인 Ortho Pharmaceutical 제약에서 유래되었습니다. 거기에서 과학자들은 OKT3라는 이름의 초기 버전 항체를 개발했습니다. 원래 쥐로부터 유래된 이 분자는 T 세포의 표면에 결합하여 그들의 세포 죽음을 막을 수 있었습니다. 1986년에는 신장 이식 후 장기 거부반응을 예방하는 데 도움이 되도록 승인되어 인간이 사용하도록 허용된 최초의 치료 항체가 되었습니다.\n",
    "    질문: OKT3는 어디에서 유래되었나요?\n",
    "    답변:\"\"\",]\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
